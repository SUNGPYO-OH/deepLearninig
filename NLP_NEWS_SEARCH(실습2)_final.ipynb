{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_NEWS_SEARCH(실습2).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uz93BS-jvKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pip install\n",
        "!pip install feedparser\n",
        "!pip install newspaper3k\n",
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InmEM7zdm6w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT LIB & URLS\n",
        "import numpy as np\n",
        "import feedparser\n",
        "from newspaper import Article\n",
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "from operator import eq\n",
        "\n",
        "urls = (\"http://rss.etnews.com/Section901.xml\", \"http://rss.etnews.com/Section902.xml\",\"http://rss.etnews.com/Section903.xml\",None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eExqsDp3l5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fileload():\n",
        "  f = open(\"./korea.txt\", 'r', encoding='utf-8')\n",
        "  stopwords = []\n",
        "  for line in f.readlines():\n",
        "    stopwords.append(line.rstrip())\n",
        "  f.close()\n",
        "  # stop_words = set(stopwords.words('korea'))\n",
        "  #print(stopwords)\n",
        "  return stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH641bEhIMmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNCTION (1) : 기사본문 중 50개의 단어 품사별로\n",
        "def get_tags(text,ntags=50):\n",
        "  num_unique_words=0\n",
        "  num_most_freq=[]\n",
        "  word_name=[]\n",
        "  stopwords = fileload()\n",
        "\n",
        "  spliter=Okt() # SPLIT -> 품사별로 나눠주는 오퍼레이터\n",
        "  nouns = spliter.nouns(text)\n",
        "  delete=[]\n",
        "  # result=[word for word in word_name if not word in stopwords]\n",
        "  for w in nouns: \n",
        "    if w not in stopwords: \n",
        "      delete.append(w) \n",
        "  count = Counter(delete) # 명사와 나오는 횟수 리턴해줌\n",
        "  return_list = []\n",
        "\n",
        "  for n,c in count.most_common(ntags) :#most_common : count를 sorting 해줌\n",
        "    num_unique_words += 1\n",
        "    word_name.append(n)\n",
        "    num_most_freq.append(c)\n",
        "  return word_name, num_unique_words, num_most_freq# 리턴 값 = 단어 수, 빈도, 전체 # return num_unique_words, num_most_freq, return_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gag0DyiEJgGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNCTION (3) : urls의 제목과 링크를 어펜드 & 리턴\n",
        "def crawl_rss(urls):\n",
        "  arr_rss = []\n",
        "  for url in urls:\n",
        "    #print(\"Success Crawl\",url)\n",
        "    parse_rss = feedparser.parse(url)\n",
        "    for p in parse_rss.entries: #entries\n",
        "      arr_rss.append({'title':p.title, 'link':p.link}) # descriptions X : 일부만 보여주기 때문에, 링크 타고가서 전부 읽어와야 => 타이틀, 링크만 가져온다\n",
        "  return arr_rss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFrFynyhM3HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FUNCTION (4) : url 한개 들어오면, 다운로드 & 파싱 => 제목이랑 내용 리턴\n",
        "def crawl_article(url, language='ko'):\n",
        "  #print(\"Success Article\",url)\n",
        "  var_article = Article(url, language = language)\n",
        "  var_article.download()\n",
        "  var_article.parse()\n",
        "  return var_article.title, var_article.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V46NdLc4xfz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spliter = Okt() \n",
        "article_list = crawl_rss(urls)\n",
        "#print(article_list)\n",
        "clean_text = []\n",
        "for article in article_list:\n",
        "  _, text = crawl_article(article['link'])\n",
        "  article['text'] = text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgFs76Mq9fGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MAIN : 실습(2) : 많이 나온 단어 순서대로 출력하기\n",
        "word_list = []\n",
        "num_list = []\n",
        "result ={}\n",
        "temp = {}\n",
        "\n",
        "# Text Parsing\n",
        "print('[Parsing Text]')\n",
        "for article in article_list:\n",
        "  word_name, num_unique_words, num_most_freq= get_tags(article['text'], 10000)\n",
        "  word_list.extend(word_name)\n",
        "  num_list.extend(num_most_freq)\n",
        "\n",
        "# 중복제거\n",
        "for key_check in set(word_list):\n",
        "  tmp = 0\n",
        "  for key, value in zip(word_list,num_list):\n",
        "    if key_check == key:\n",
        "      tmp += value\n",
        "  result[key_check] = tmp\n",
        "\n",
        "# 정렬\n",
        "result = sorted(result.items(), key = lambda x : x[1], reverse = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR0l3Q1Ryg1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}